---
title: 'Information Theory, chapter 1: the Science of Information'
date: 2022-09-14
permalink: /posts/2022/09/Information Theory/
tags:
  - notebook
  - Information Theory
  - category2
---

This is the notebook for the course ''[Information Theory](https://www.coursera.org/learn/information-theory)'' provided by Coursera and CUHK.

a high level introduction for Information Theory

# 1. Information Theory

- Founded by Claude E. Shannon (1916-2001)

- "[The Mathematical Theory of Communication](https://cse.buffalo.edu/~hungngo/classes/2003/Markov_Chains/papers/p3-shannon.pdf)", 1948

- Study fundamental limits in communications: transmission, storage, etc

- ![schematic_diagram_of_a_general_communication_system](.\figure\schematic_diagram_of_a_general_communication_system.png)

# 2. Two Key Concepts

- Information is **uncertainty**: 
  - an information source is modeled as random variable
  - there must be uncertainty associated with the information source, otherwise it does not need to be transmitted at all
- Information is **digital**:
  - transmission should be 0's and 1's (bits) with no reference to what they represent

# 3. Two Fundamental Theorems

- **Source coding theorem**
  - fundamental limit in data compression (zip, MP3, JPEG, MPEG etc)
  - no matter how smart the data compression algorithm is designed, there is always a minimum size that the file can be compressed (this is what it means by a fundamental limit)
- **Channel coding theorem**
  - fundamental limit for reliable communication through a noisy channel (telephone, cell phone, modem, data storage, etc)
  - no matter how smart the communication (system) is designed, for reliable communication, there exists a maximum rate that information can be transmitted through the channel (this quantity is called the *channel capacity*)
